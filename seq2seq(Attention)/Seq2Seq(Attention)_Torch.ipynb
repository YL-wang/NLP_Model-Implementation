{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ich', 'mochte', 'ein', 'bier', 'P', 'S', 'i', 'want', 'a', 'beer', 'i', 'want', 'a', 'beer', 'E']\n",
      "['ein', 'beer', 'S', 'a', 'ich', 'E', 'i', 'P', 'mochte', 'bier', 'want']\n",
      "{'ein': 0, 'beer': 1, 'S': 2, 'a': 3, 'ich': 4, 'E': 5, 'i': 6, 'P': 7, 'mochte': 8, 'bier': 9, 'want': 10}\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "word_list = \" \".join(sentences).split()\n",
    "print(word_list)\n",
    "word_list = list(set(word_list))\n",
    "print(word_list)\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "print(word_dict)\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "print(n_class)\n",
    "# Parameter\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = Variable(torch.empty([n_step, 1, n_class]))\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = Variable(torch.zeros(n_step))  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 11])\n",
      "torch.Size([1, 5, 11])\n",
      "torch.Size([1, 5])\n",
      "1\n",
      "tensor([[ 6, 10,  3,  1,  5]])\n",
      "torch.Size([1, 1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyili/anaconda3/envs/python3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "print(input_batch.shape)\n",
    "print(output_batch.shape)\n",
    "print(target_batch.shape)\n",
    "#print(input_batch)\n",
    "print(len(output_batch))\n",
    "print(target_batch)\n",
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = Variable(torch.zeros(1, 1, n_hidden))\n",
    "print(hidden.shape)\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyili/anaconda3/envs/python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000470\n",
      "Epoch: 0800 cost = 0.000153\n",
      "Epoch: 1200 cost = 0.000076\n",
      "Epoch: 1600 cost = 0.000045\n",
      "Epoch: 2000 cost = 0.000029\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyili/anaconda3/envs/python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'PPPPP']]]\n",
    "test_batch = Variable(torch.Tensor(test_batch))\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq(Attention)-Torch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:python3.6]",
   "language": "python",
   "name": "conda-env-python3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
